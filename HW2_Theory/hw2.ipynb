{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "1. Add your name and HW Group Number below.\n",
    "2. Complete each question. Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\".\n",
    "3. Where applicable, run the test cases *below* each question to check your work. **Note**: In addition to the test cases you can see, the instructor may run additional test cases, including using *other datasets* to validate you code.\n",
    "4. Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All). You can also use the **Validate** button to run all test cases.\n",
    "5. Turn in your homework by going to the main screen in JupyterHub, clicking the Assignments menu, and submitting. **Also** make sure to turn in your homework on Moodle (so we have a backup copy).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nName: Rahul Yedida\\nHW Group Number: 1\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Name: Rahul Yedida\n",
    "HW Group Number: 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cd78efd40dfbf865fe47aa923d891b1c",
     "grade": false,
     "grade_id": "cell-79604674b02e9546",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Homework 2\n",
    "\n",
    "## Classification and Cross Validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e49d5f9b96799f65a64a8faf9a916d09",
     "grade": false,
     "grade_id": "cell-ca39a2ee06ae6f53",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Import all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76785fab6bacd3211b77ae3c00560425",
     "grade": false,
     "grade_id": "cell-080202b19ef83038",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# you should be familiar with numpy, pandas and matplotlib from HW0\n",
    "import numpy as np\n",
    "# set a seed for reproducibility\n",
    "np.random.seed(23)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# we're using the Diabetes dataset from sklearn.datasets\n",
    "from sklearn import datasets\n",
    "\n",
    "# we will also be using the DecisionTreeClassifier library from scikit learn for this exercise\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# we will use the MinMaxScaler method to scale our data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# to generate k-folds from the data\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "# we will also use sklearn.metrics to calculate a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# to calulate distance matrix\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# Remember you have to run this cell block before continuing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b722d3761d3158c482a9c7f2a811621a",
     "grade": false,
     "grade_id": "cell-a40c01cfb0407a04",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Data\n",
    "\n",
    "We'll be using the Wine dataset from previous exercises for this homework.\n",
    "Please note that we've already split the dataset into three parts:\n",
    "* a ***wine_train.csv*** which is used to train your models\n",
    "* a ***wine_test.csv*** which you will use to evaluate your models\n",
    "* another dataset, having the same properties as wine_train and wine_test to be used by the TAs for grading. This is not provided to you and will be used as part of grading your solutions.\n",
    "\n",
    "You are provided the following variables:\n",
    "\n",
    "* ```wine_train_x```: a numpy array referring to the features in training data. Each row is a separate data point and each column refers to the features.\n",
    "* ```wine_train_y```: a numpy array of shape refers to the class variable in training data.\n",
    "* ```wine_test_x```: a numpy array referring to the features in test data. Each row is a separate data point and each column refers to the features. Test data and training data have the same features. \n",
    "* ```wine_test_y```: a numpy array referring to the class variable in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61be52e1f48a986f812691f06adb17f0",
     "grade": false,
     "grade_id": "cell-2544593fc499757f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "wine_train = pd.read_csv('/etc/data/wine_train.csv')\n",
    "wine_test = pd.read_csv('/etc/data/wine_test.csv')\n",
    "\n",
    "# split the training data frame into features and class variables for use later. \n",
    "# take a look at the variable names and their descriptions in the cell above.\n",
    "wine_train_y = wine_train['Wine_Type'].values\n",
    "wine_train_x = wine_train.drop(['Wine_Type'], axis=1).values\n",
    "\n",
    "# now do the same with test data\n",
    "wine_test_y = wine_test['Wine_Type'].values\n",
    "wine_test_x = wine_test.drop(['Wine_Type'], axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "04ce145d6ae93bc0cc4780890bd90da2",
     "grade": false,
     "grade_id": "cell-f243722296d2b41f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Problem 1.1: Evaluation Measures\n",
    "In this 2-part problem, you will be writing code to calculate accuracy, precision, recall and f1 score **by hand**, from a confusion matrix generated by sklearn.\n",
    "\n",
    "*Note*: In practice, sklearn offers methods to calculate each of these scores, but you are asked to calculate them by hand to practice working with a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e89c00144302f04eea773bb8b63b4c29",
     "grade": false,
     "grade_id": "cell-c5f7551ee8669b49",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluation_measures(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Write a single function to calculate accuracy and a confusion matrix for the given data\n",
    "    Input:\n",
    "        y_true: A numpy array containing the actual ground truth labels\n",
    "        y_pred: A numpy array containing the predicted labels from a model (such as a decision tree or knn classifier)\n",
    "                y_pred has the same dimensions as y_true\n",
    "                \n",
    "    Output:\n",
    "        A list in the following order:\n",
    "        overall accuracy score, confusion matrix\n",
    "    \n",
    "    Allowed Libraries: sklearn.metrics.confusion_matrix and np methods *only* (no other sklearn metrics)\n",
    "    \n",
    "    Hint: Take a look at confusion_matrix method from sklearn.metrics\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    confusion = confusion_matrix(y_true, y_pred)\n",
    "    acc = sum([confusion[i][i] for i in range(len(confusion))]) / np.sum(confusion)\n",
    "    \n",
    "    return [acc, confusion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the dummy data is 0.8333333333333334\n",
      "Confusion Matrix is\n",
      "[[2 0]\n",
      " [1 3]]\n"
     ]
    }
   ],
   "source": [
    "# Test your code!\n",
    "# creating two random roles\n",
    "true_labels = np.array([0, 1, 1, 0, 1, 1]) \n",
    "pred_labels = np.array([0, 0, 1, 0, 1, 1]) \n",
    "accuracy, cm = evaluation_measures(y_true=true_labels, y_pred=pred_labels)\n",
    "# Note: sklearn's Confusion matrix puts true negatives in M[0, 0], but you may be\n",
    "# used to seeing them at [1, 1] from the slides in class. Read the documentation.\n",
    "print(f'Accuracy of the dummy data is {accuracy}\\nConfusion Matrix is\\n{cm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c1a31619fcb6996b619ae995c93fdb06",
     "grade": true,
     "grade_id": "evaluation_measures-public",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "true_labels = np.array([0, 1, 1, 0, 1, 1]) \n",
    "pred_labels = np.array([0, 0, 1, 0, 1, 1]) \n",
    "evaluation_results = evaluation_measures(y_true=true_labels, y_pred=pred_labels)\n",
    "assert type(evaluation_results) == list\n",
    "assert len(evaluation_results) == 2\n",
    "np.testing.assert_almost_equal(evaluation_results[0], 0.8333333333333334)\n",
    "np.testing.assert_equal(evaluation_results[1], np.array([[2, 0], [1, 3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "637e82498fadbdd07ee68792343737b8",
     "grade": true,
     "grade_id": "evaluation_measures-hidden",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Remember, we will also use hidden test cases - you should create your own too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79bdca0f43ca32efb34fb96dcc8330e2",
     "grade": false,
     "grade_id": "cell-d3038fef07ae9726",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluation_measures2(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Write a single function to calculate precision, recall and f1 score for the given data.\n",
    "    Input: Two binary vectors of 0s (negative class) or 1s (positive class)\n",
    "        y_true: A numpy array containing the actual ground truth labels\n",
    "        y_pred: A numpy array containing the predicted labels from a model (such as a decision tree or knn classifier)\n",
    "                y_pred has the same dimensions as y_true\n",
    "                \n",
    "    Output:\n",
    "        A list in the following order:\n",
    "        precision, recall, f1-score\n",
    "        \n",
    "    Note: You can assume there are only 2 classes, 1 (positive) and 0 (negative)\n",
    "    \n",
    "    Allowed Libraries: sklearn.metrics.confusion_matrix and np methods *only* (no other sklearn metrics)\n",
    "    \n",
    "    Hint: Take a look at confusion_matrix method from sklearn.metrics\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    prec = tp / (tp + fp)# if tp + fp != 0 else 0\n",
    "    rec = tp / (tp + fn) #if tp + fn != 0 else 0\n",
    "    f1 = 2 * prec * rec / (prec + rec) if prec + rec != 0 else 0\n",
    "    \n",
    "    return [prec, rec, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0\n",
      "Recall: 0.75\n",
      "F1: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "# Test your code!\n",
    "# creating two random roles\n",
    "true_labels = np.array([0, 1, 1, 0, 1, 1]) \n",
    "pred_labels = np.array([0, 0, 1, 0, 1, 1]) \n",
    "precision, recall, f1 = evaluation_measures2(y_true=true_labels, y_pred=pred_labels)\n",
    "# Calculate these values by hand - are they correct?\n",
    "print(f'Precision: {precision}\\nRecall: {recall}\\nF1: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7cee1bffaefaa262b376ac7002a6407d",
     "grade": true,
     "grade_id": "evaluation_measures2-public",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "true_labels = np.array([0, 1, 1, 0, 1, 1]) \n",
    "pred_labels = np.array([0, 0, 1, 0, 1, 1]) \n",
    "evaluation_results = evaluation_measures2(y_true=true_labels, y_pred=pred_labels)\n",
    "assert type(evaluation_results) == list\n",
    "assert len(evaluation_results) == 3\n",
    "np.testing.assert_almost_equal(evaluation_results[0], 3/3)\n",
    "np.testing.assert_almost_equal(evaluation_results[1], 3/4)\n",
    "np.testing.assert_almost_equal(evaluation_results[2], 3/3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e99882a4cb2903884d257ceb31d5862",
     "grade": true,
     "grade_id": "evaluation_measures2-hidden",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Remember, we will also use hidden test cases - you should create your own too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40d5f65206f60db6bf8efb172559e8e3",
     "grade": false,
     "grade_id": "cell-72b5a8eeb6cd3177",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ed6869856189485bd97c67520247cf2",
     "grade": false,
     "grade_id": "cell-cacb4e76a76592ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Examples\n",
    "\n",
    "You can perform classification using a DecisionTree in python using the scikit-learn library. \n",
    "\n",
    "Take a look at the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier) to get a clear understanding of all function arguments.\n",
    "\n",
    "Given below is a simple toy example for you to learn how to use the DecisionTreeClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels shape is (50,)\n",
      "Accuracy of your model is 0.96,\n",
      "Confusion matrix is:\n",
      " [[19  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  2 14]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(133.92000000000002, 199.32, 'X[3] <= 0.292\\ngini = 0.666\\nsamples = 100\\nvalue = [31, 35, 34]'),\n",
       " Text(100.44000000000001, 163.07999999999998, 'gini = 0.0\\nsamples = 31\\nvalue = [31, 0, 0]'),\n",
       " Text(167.40000000000003, 163.07999999999998, 'X[2] <= 0.653\\ngini = 0.5\\nsamples = 69\\nvalue = [0, 35, 34]'),\n",
       " Text(66.96000000000001, 126.83999999999999, 'X[3] <= 0.667\\ngini = 0.059\\nsamples = 33\\nvalue = [0, 32, 1]'),\n",
       " Text(33.480000000000004, 90.6, 'gini = 0.0\\nsamples = 31\\nvalue = [0, 31, 0]'),\n",
       " Text(100.44000000000001, 90.6, 'X[0] <= 0.485\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 1, 1]'),\n",
       " Text(66.96000000000001, 54.359999999999985, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(133.92000000000002, 54.359999999999985, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(267.84000000000003, 126.83999999999999, 'X[3] <= 0.688\\ngini = 0.153\\nsamples = 36\\nvalue = [0, 3, 33]'),\n",
       " Text(234.36, 90.6, 'X[2] <= 0.737\\ngini = 0.5\\nsamples = 6\\nvalue = [0, 3, 3]'),\n",
       " Text(200.88000000000002, 54.359999999999985, 'X[1] <= 0.146\\ngini = 0.375\\nsamples = 4\\nvalue = [0, 3, 1]'),\n",
       " Text(167.40000000000003, 18.119999999999976, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(234.36, 18.119999999999976, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(267.84000000000003, 54.359999999999985, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(301.32000000000005, 90.6, 'gini = 0.0\\nsamples = 30\\nvalue = [0, 0, 30]')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's use a toy dataset to demonstrate DecisionTreeClassifier. \n",
    "# We are using the iris dataset from sklearn.datasets as our toy dataset.\n",
    "# We will apply DecisionTreeClassifier on it and perform classification. \n",
    "# we will use train_test_split from Sklearn to split our data into training and testing in a stratified manner\n",
    "# first, load the data\n",
    "toy_dataset_sk = datasets.load_iris()\n",
    "toy_labels = toy_dataset_sk.target\n",
    "\n",
    "# split into train and test in a stratified manner\n",
    "toy_dataset_train, toy_dataset_test, toy_labels_train, toy_labels_test = train_test_split(toy_dataset_sk.data, \n",
    "                                                                                          toy_labels, \n",
    "                                                                                          test_size = 0.33)\n",
    "\n",
    "# scale the train and test datasets\n",
    "# note that we fit the scaler only on the training dataset, since we\n",
    "# should not \"leak\" information from the test dataset (e.g. it's mean, sd)\n",
    "# into the model\n",
    "toy_scaler = MinMaxScaler().fit(toy_dataset_train)\n",
    "toy_dataset_train = toy_scaler.transform(toy_dataset_train)\n",
    "toy_dataset_test = toy_scaler.transform(toy_dataset_test)\n",
    "\n",
    "# apply DecisionTreeClassifier on the toy dataset \n",
    "# in this case, we're using the gini index to split the data\n",
    "# first initialize the DecisionTreeClassifier variable\n",
    "# we'll also set the seed to 23 for reproducibility\n",
    "toy_decision_tree = DecisionTreeClassifier(criterion='gini', random_state=23)\n",
    "# now, train the model\n",
    "toy_decision_tree.fit(X=toy_dataset_train, y=toy_labels_train)\n",
    "# predict on the test set\n",
    "toy_predictions = toy_decision_tree.predict(X=toy_dataset_test)\n",
    "\n",
    "# evaluate your model and print the accuracy \n",
    "toy_evaluations = evaluation_measures(y_true=toy_labels_test, y_pred=toy_predictions)\n",
    "\n",
    "# print the evaluation of the model\n",
    "print(f'Predicted labels shape is {toy_labels_test.shape}\\nAccuracy of your model is {toy_evaluations[0]},\\\n",
    "\\nConfusion matrix is:\\n {toy_evaluations[1]}')\n",
    "\n",
    "# print the tree itself, using the sklearn.tree.plot_tree function\n",
    "plot_tree(toy_decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1.2: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e3cf3769cab6a06f9f7e592cf11df4a",
     "grade": false,
     "grade_id": "cell-7343ef047a51a9e2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def dtree(x_train, y_train, x_test, criterion, random_state):\n",
    "    \"\"\"\n",
    "    Using the example above, you will build a decision tree using the x_train and y_train and predict using x_test.\n",
    "    Your inputs and outputs are as shown below:\n",
    "    \n",
    "    Input:\n",
    "          x_train: A numpy array of shape (n_training_rows, n_attributes) where n_training_rows refers to \n",
    "          the number of rows in your training dataset and n_attributes refers to the number of attributes. \n",
    "          y_train: A numpy array of shape (n_training_rows, ) containing the class labels for each row in your \n",
    "          training dataset.\n",
    "          x_test: A numpy array of shape (n_testing_rows, n_attributes) where n_testing_rows refers to the number \n",
    "          of rows in your testing dataset and n_attributes refers to the number of attributes. \n",
    "          criterion: A string variable, can be either 'entropy' or 'gini'\n",
    "          random_state: An integer to specify the random seed for the classifier (this creates deterministic output)\n",
    "          \n",
    "    Output:\n",
    "          A numpy array of shape (n_testing_rows, ) containing the predicted labels for each row in your testing dataset. \n",
    "    Allowed Libraries: sklearn\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    tree = DecisionTreeClassifier(criterion=criterion, random_state=random_state)\n",
    "    tree.fit(x_train, y_train)\n",
    "    \n",
    "    return tree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels shape is (40,)\n",
      "Accuracy of your model is 0.95\n",
      "Confusion matrix of your model is\n",
      " [[15  0  0]\n",
      " [ 0 13  2]\n",
      " [ 0  0 10]]\n"
     ]
    }
   ],
   "source": [
    "# Test your code!\n",
    "wine_dtree_predictions = dtree(x_train=wine_train_x, y_train=wine_train_y,\n",
    "                               x_test=wine_test_x, \n",
    "                               criterion='gini', \n",
    "                               random_state=23)\n",
    "wine_dtree_evaluations = evaluation_measures(y_true=wine_test_y,\n",
    "                                    y_pred=wine_dtree_predictions)\n",
    "print(f'Predicted labels shape is {wine_dtree_predictions.shape}\\\n",
    "\\nAccuracy of your model is {wine_dtree_evaluations[0]}\\\n",
    "\\nConfusion matrix of your model is\\n {wine_dtree_evaluations[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af0d65a180f8e44808f464487397f632",
     "grade": true,
     "grade_id": "dtree-public",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "wine_dtree_predictions = dtree(x_train=wine_train_x, y_train=wine_train_y,\n",
    "                               x_test=wine_test_x, \n",
    "                               criterion='entropy', \n",
    "                               random_state=23)\n",
    "wine_dtree_evaluations = evaluation_measures(y_true=wine_test_y,\n",
    "                                    y_pred=wine_dtree_predictions)\n",
    "assert wine_dtree_predictions.shape[0] == 40\n",
    "np.testing.assert_equal(wine_dtree_evaluations[0], 0.9)\n",
    "wine_confusion_matrix = np.array([[14, 1, 0], [2, 12, 1], [0, 0, 10]])\n",
    "np.testing.assert_equal(wine_dtree_evaluations[1], wine_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "75bb6b634286ab91597f779fe1cba6b4",
     "grade": true,
     "grade_id": "dtree-hidden",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Remember, we will also use hidden test cases - you should create your own too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "874f70ee39b2ced5af8942fbb214f8ea",
     "grade": false,
     "grade_id": "cell-f5027607b9e09be7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Problem 1.3: k - Nearest Neighbors\n",
    "\n",
    "In HW1, we evaluated some distances (cosine, euclidean). Now we'll use them to perform classification using the K-Nearest Neighbors algorithm. \n",
    "\n",
    "\n",
    "## Instructions\n",
    "Please read the following instructions carefully before implementing your method:\n",
    "\n",
    "* **NOTE 1:** In this exercise, you're being asked to **implement** the K-Nearest Neighbors algorithm. Using the standard knn methods from sklearn or any builtin knn methods will result in an automatic zero.\n",
    "\n",
    "* **NOTE 2:** In case of conflicts, with equal nearest neighbors of different classes, choose the class with lower numerical value. E.g.: in 4NN, if you have 2 NN of class 1, 2 NN of class 2, there is a conflict b/w class 1 and class 2\n",
    "  In this case, you will choose class 1. \n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83aad0e43c23588a6416a6e2a3fde029",
     "grade": false,
     "grade_id": "cell-91bcee684751b640",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Some useful functions for the knn method\n",
    "def calculate_distance_matrix(x_test , x_train, distance_type):\n",
    "    \"\"\"\n",
    "    This method calculates the distance matrix required for KNN classifier\n",
    "    Use this method to make your distance calculations easy.\n",
    "    \n",
    "    Input: x_test and x_train are two numpy matrices referring to the test features and train features respectively. \n",
    "           distance_type is a string specifying the type of distance. Can be 'euclidean_distance' or 'cosine_distance'\n",
    "    Output: A matrix of shape (test_rows, train_rows), where the item at index [i, j] is the distance between\n",
    "            x_test[i] and x_train[j].\n",
    "    \"\"\"\n",
    "    if distance_type == 'euclidean_distance':\n",
    "        return pairwise_distances(x_test, x_train, metric='euclidean')\n",
    "    elif distance_type == 'cosine_distance':\n",
    "        return pairwise_distances(x_test, x_train, metric='cosine')\n",
    "    else:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0caae12faee5c3a398c90bec7df768fd",
     "grade": false,
     "grade_id": "cell-5a689b1d4f0e64e5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Some examples that may help you with the exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the toy_distance_matrix is (50, 100)\n",
      "\n",
      "Distances of the 1st test instance to the first 20 rows in the training data, respectively: \n",
      "[0.24139627 0.25486661 1.21078229 0.43009841 0.53117037 0.31897809\n",
      " 0.43671289 0.43830209 1.2008583  0.1410621  0.19383105 1.20912393\n",
      " 0.58737102 1.06063354 0.19596018 0.66938633 0.33451659 0.20034097\n",
      " 0.37216494 0.40413329]\n",
      "\n",
      "The indices of nearest neighbors :\n",
      "[ 9 10 14 17  0  1  5 16 18 19  3  6  7  4 12 15 13  8 11  2]\n",
      "\n",
      "The classes of the 3 nearest neighbors: [2 1 2]\n",
      "\n",
      "The classes of the test instance: 2\n"
     ]
    }
   ],
   "source": [
    "# We're using the same toy_dataset_train, toy_dataset_test, toy_labels_train, toy_labels_test\n",
    "# variables from the previous exercise. Please make sure you run that cell before running this.\n",
    "\n",
    "# let us compute the euclidean distance matrix between toy_dataset_train and toy_dataset_test\n",
    "toy_knn_distance_matrix = calculate_distance_matrix(\n",
    "    toy_dataset_test, toy_dataset_train, 'euclidean_distance')\n",
    "\n",
    "# check the shape of the toy_distance_matrix. \n",
    "# It is the distance from the 50 test points to every training point (100 in total). \n",
    "# So the shape should be (50, 100)\n",
    "print(f'Shape of the toy_distance_matrix is {toy_knn_distance_matrix.shape}\\n')\n",
    "\n",
    "first_instance_distances = toy_knn_distance_matrix[0,0:20]\n",
    "print('Distances of the 1st test instance to the first 20 rows in the ' +\n",
    "      f'training data, respectively: \\n{first_instance_distances}\\n')\n",
    "\n",
    "# argsort sorts an array, but it returns the *indexes* of the items in original array, in sorted order\n",
    "# See: https://numpy.org/doc/stable/reference/generated/numpy.argsort.html\n",
    "sorted_indices = np.argsort(first_instance_distances)\n",
    "# Note that the first item is 9, and index 9 (0-based) of the distances is 0.1410621, the lowest value\n",
    "print(f'The indices of nearest neighbors :\\n{sorted_indices}')\n",
    "\n",
    "# Indices of the nearest 3 neighbors (in the first 20 rows of the training dataset)\n",
    "nearest_neighbor_indices = sorted_indices[:3]\n",
    "nn_classes = toy_labels_train[nearest_neighbor_indices]\n",
    "print (f'\\nThe classes of the 3 nearest neighbors: {nn_classes}')\n",
    "print (f'\\nThe classes of the test instance: {toy_labels_test[0]}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.3\r\n"
     ]
    }
   ],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "41a06ee96b6f1c9b14be73bbdebfc213",
     "grade": false,
     "grade_id": "cell-03d5cf564294ded3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def knn(x_train, y_train, x_test, k, distance_type):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "          x_train: A numpy array of shape (n_training_rows, n_attributes) where n_training_rows refers to \n",
    "          the number of rows in your training dataset and n_attributes refers to the number of attributes. \n",
    "          y_train: A numpy array of shape (n_training_rows, ) containing the class labels for each row in your \n",
    "          training dataset.\n",
    "          x_test: A numpy array of shape (n_testing_rows, n_attributes) where n_testing_rows refers to the number \n",
    "          of rows in your testing dataset and n_attributes refers to the number of attributes.\n",
    "          k: An integer specifying the number of nearest neighbors \n",
    "          distance_type: A string describing the type of distance (can be 'cosine_distance' or 'euclidean_distance')\n",
    "          \n",
    "    Output:\n",
    "           A numpy vector of the shape (n_testing_rows, ) containing the predicted labels for each testing data point.\n",
    "            \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    dist = calculate_distance_matrix(x_test, x_train, distance_type)\n",
    "    nearest = np.argsort(dist, axis=1)[:,:k]\n",
    "    nearest_labels = y_train[nearest]\n",
    "    \n",
    "    def get_mode(x): \n",
    "        ctr = Counter(x)\n",
    "        common = ctr.most_common()\n",
    "        amax = max(common, key=lambda p: p[1])[1]\n",
    "        maxes = list(filter(lambda p: p[1] == amax, common))\n",
    "        return min(maxes, key=lambda p: p[0])[0]\n",
    "    \n",
    "    return np.array(list(map(get_mode, nearest_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 2), (0, 1)]\n",
      "2\n",
      "[(1, 2)]\n",
      "[(1, 2), (2, 1)]\n",
      "2\n",
      "[(1, 2)]\n",
      "[(0, 3)]\n",
      "3\n",
      "[(0, 3)]\n",
      "[(0, 2), (1, 1)]\n",
      "2\n",
      "[(0, 2)]\n",
      "[(0, 2), (1, 1)]\n",
      "2\n",
      "[(0, 2)]\n",
      "[(0, 3)]\n",
      "3\n",
      "[(0, 3)]\n",
      "[(0, 3)]\n",
      "3\n",
      "[(0, 3)]\n",
      "[(0, 3)]\n",
      "3\n",
      "[(0, 3)]\n",
      "[(1, 2), (0, 1)]\n",
      "2\n",
      "[(1, 2)]\n",
      "[(0, 3)]\n",
      "3\n",
      "[(0, 3)]\n",
      "[(2, 3)]\n",
      "3\n",
      "[(2, 3)]\n",
      "[(0, 3)]\n",
      "3\n",
      "[(0, 3)]\n",
      "[(0, 3)]\n",
      "3\n",
      "[(0, 3)]\n",
      "[(0, 3)]\n",
      "3\n",
      "[(0, 3)]\n",
      "[(0, 2), (1, 1)]\n",
      "2\n",
      "[(0, 2)]\n",
      "[(1, 3)]\n",
      "3\n",
      "[(1, 3)]\n",
      "[(0, 3)]\n",
      "3\n",
      "[(0, 3)]\n",
      "[(0, 3)]\n",
      "3\n",
      "[(0, 3)]\n",
      "[(2, 3)]\n",
      "3\n",
      "[(2, 3)]\n",
      "[(0, 3)]\n",
      "3\n",
      "[(0, 3)]\n",
      "[(1, 3)]\n",
      "3\n",
      "[(1, 3)]\n",
      "[(1, 2), (0, 1)]\n",
      "2\n",
      "[(1, 2)]\n",
      "[(2, 3)]\n",
      "3\n",
      "[(2, 3)]\n",
      "[(1, 3)]\n",
      "3\n",
      "[(1, 3)]\n",
      "[(1, 3)]\n",
      "3\n",
      "[(1, 3)]\n",
      "[(2, 2), (1, 1)]\n",
      "2\n",
      "[(2, 2)]\n",
      "[(0, 3)]\n",
      "3\n",
      "[(0, 3)]\n",
      "[(2, 3)]\n",
      "3\n",
      "[(2, 3)]\n",
      "[(1, 2), (2, 1)]\n",
      "2\n",
      "[(1, 2)]\n",
      "[(0, 3)]\n",
      "3\n",
      "[(0, 3)]\n",
      "[(2, 3)]\n",
      "3\n",
      "[(2, 3)]\n",
      "[(0, 3)]\n",
      "3\n",
      "[(0, 3)]\n",
      "[(0, 3)]\n",
      "3\n",
      "[(0, 3)]\n",
      "[(1, 3)]\n",
      "3\n",
      "[(1, 3)]\n",
      "[(2, 3)]\n",
      "3\n",
      "[(2, 3)]\n",
      "[(2, 3)]\n",
      "3\n",
      "[(2, 3)]\n",
      "[(1, 3)]\n",
      "3\n",
      "[(1, 3)]\n",
      "[(2, 3)]\n",
      "3\n",
      "[(2, 3)]\n",
      "[(2, 3)]\n",
      "3\n",
      "[(2, 3)]\n",
      "[(1, 3)]\n",
      "3\n",
      "[(1, 3)]\n",
      "Predicted labels shape is (40,) \n",
      "Accuracy of your model is 0.925\n",
      "Confusion Matrix is\n",
      "[[15  0  0]\n",
      " [ 3 12  0]\n",
      " [ 0  0 10]]\n"
     ]
    }
   ],
   "source": [
    "# Test your code!\n",
    "wine_knn_predictions =  knn(x_train=wine_train_x, y_train=wine_train_y,\n",
    "                               x_test=wine_test_x, \n",
    "                               k=3,\n",
    "                               distance_type='cosine_distance')\n",
    "wine_knn_evaluations = evaluation_measures(y_true=wine_test_y, y_pred=wine_knn_predictions)\n",
    "print(f'Predicted labels shape is {wine_knn_predictions.shape} \\nAccuracy of your model is {wine_knn_evaluations[0]}\\n\\\n",
    "Confusion Matrix is\\n{wine_knn_evaluations[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "577f7fba22ef2b4039f65a5a4e1fec47",
     "grade": true,
     "grade_id": "knn",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "wine_knn_predictions =  knn(x_train=wine_train_x, y_train=wine_train_y,\n",
    "                               x_test=wine_test_x, \n",
    "                               k=3,\n",
    "                               distance_type='euclidean_distance')\n",
    "wine_knn_evaluations = evaluation_measures(y_true=wine_test_y, y_pred=wine_knn_predictions)\n",
    "assert wine_knn_predictions.shape[0] == 40\n",
    "np.testing.assert_equal(wine_knn_evaluations[0], 0.9)\n",
    "np.testing.assert_equal(wine_knn_evaluations[1], [[15,0,0], [3,12,0], [0,1,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53adc5e5e83dbf8255bf380475fa041d",
     "grade": true,
     "grade_id": "knn_hidden",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Remember, we will also use hidden test cases - you should create your own too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b236b80cb7788a9f915a6fd2a2239ff2",
     "grade": false,
     "grade_id": "cell-a21add375a4a9ad3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Problem 4: k-Fold Cross Validation (522: required; 422: bonus)\n",
    "\n",
    "In the next part of this homework, we'll work on k-fold cross validation. \n",
    "We can create random folds using the [KFold method](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)\n",
    "\n",
    "Let us start with some examples.\n",
    "\n",
    "**Note**: This problem is not required for CSC 422 students, but if completed will count towards extra credit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will initialize n-folds for k-fold cross validation using the KFold method\n",
    "# to create 3 folds set n_folds to 3, shuffle to True and then random_state to 23 for reproducibility\n",
    "toy_k_fold_cv = KFold(n_splits=3, shuffle=True, random_state=23)\n",
    "\n",
    "# let's see which indices are split into train and validation\n",
    "# we'll use the split method which is part of k_fold_cv to extract training and validation splits for each fold\n",
    "\n",
    "# let's keep track of which fold each instance is in\n",
    "folds = [0] * len(toy_dataset_train)\n",
    "\n",
    "fold = 0;\n",
    "for toy_train_indices, toy_val_indices in toy_k_fold_cv.split(toy_dataset_train):\n",
    "    print(f'Fold# {fold}: \\nTraining indices: {toy_train_indices} \\nValidation indices: {toy_val_indices}\\n')\n",
    "    \n",
    "    # for each split, extract the training and validation split (unused here)\n",
    "    toy_train_x_split, toy_val_x_split = toy_dataset_train[toy_train_indices, :], toy_dataset_train[toy_val_indices]\n",
    "    toy_train_y_split, toy_val_y_split = toy_labels_train[toy_train_indices], toy_labels_train[toy_val_indices]\n",
    "    \n",
    "    # keep track of the fold # of each row in the training dataset\n",
    "    for index in toy_val_indices:\n",
    "        folds[index] = fold\n",
    "    \n",
    "    fold += 1\n",
    "    \n",
    "print(folds)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "85bb78386e2b39801e0262e05dd85c12",
     "grade": false,
     "grade_id": "cell-565931d268b643fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Implement a method to fully implement crossvalidation to evaluate the knn method you implemented above. This function takes the n_splits (number of folds/splits), the k value for knn, and the distance method for knn as arguments. See the comments below for a complete overview of the function arguments. \n",
    " \n",
    "Your function should return a list of per-fold accuracies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a372f452bd42449a0d91da3853358b09",
     "grade": false,
     "grade_id": "cell-8f9d427a59b09bb3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def kfold_cross_validation(x_train, y_train, n_splits, k_for_knn, distance_type, random_state):\n",
    "    \"\"\"\n",
    "    Write a function that takes training data as x_train, labels as y_train, n_folds as number of folds and \n",
    "    performs n_folds cross validation using a decision tree classifier (use the dtree method from above) \n",
    "    and returns a list containing the accuracies of each fold.\n",
    "    \n",
    "    Input: \n",
    "         x_train: A numpy array of shape (n_training_rows, n_attributes) where n_training_rows refers to \n",
    "          the number of rows in your training dataset and n_attributes refers to the number of attributes. \n",
    "         y_train: A numpy array of shape (n_training_rows, ) containing the class labels for each row in your \n",
    "          training dataset.\n",
    "         n_splits: An integer specifying the number of splits for k-fold cross validation\n",
    "         k_for_knn: An integer indicating the number of nearest neighbors in knn\n",
    "         distance_type: A string describing the type of distance (can be 'cosine_distance' or 'euclidean_distance')\n",
    "         random_state: An integer specifying the seed for the kfolds creation \n",
    "         \n",
    "    Output:\n",
    "         A list containing floating point values containing the accuracies of each fold\n",
    "         Hint: You can use the evaluation_measures method to do this easily.\n",
    "         \n",
    "    IMPORTANT: set shuffle=True in KFold.\n",
    "    \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    accuracies = []\n",
    "    \n",
    "    k_fold_cv = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    for i, (train_idx, test_idx) in enumerate(k_fold_cv.split(x_train)):\n",
    "        x = x_train[train_idx]\n",
    "        y = y_train[train_idx]\n",
    "        xt = x_train[test_idx]\n",
    "        \n",
    "        preds = knn(x, y, xt, k_for_knn, distance_type)\n",
    "        acc = evaluation_measures(y_train[test_idx], preds)[0]\n",
    "        \n",
    "        accuracies.append(acc)\n",
    "    \n",
    "    return np.array(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your function!\n",
    "per_fold_accuracy = kfold_cross_validation(x_train=wine_train_x, \n",
    "                                           y_train=wine_train_y,\n",
    "                                           n_splits=5, \n",
    "                                           k_for_knn=5,\n",
    "                                           distance_type='cosine_distance',\n",
    "                                           random_state=23)\n",
    "\n",
    "# There should be k accuracy for k-fold crossvalidation\n",
    "print(per_fold_accuracy)\n",
    "\n",
    "# We can get the macro-average for an overall accuracy\n",
    "print(np.mean(per_fold_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens if we instead train and test on the same dataset,\n",
    "# instead of using cross-validation?\n",
    "training_predictions = knn(x_train=wine_train_x, \n",
    "                           y_train=wine_train_y, \n",
    "                           x_test=wine_train_x, \n",
    "                           k=5, distance_type='cosine_distance')\n",
    "# The accuracy is higher (by about 5%)\n",
    "evaluation_measures(y_true=wine_train_y, y_pred=training_predictions)[0]\n",
    "# Which is more representative of how the model would perform on unseen data?\n",
    "# Would this difference be higher or lower for k=10? What about k = 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "365de47e802364a6af93cbecffa50563",
     "grade": true,
     "grade_id": "kfold_cross_validation-public",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "per_fold_accuracy = kfold_cross_validation(x_train=wine_train_x, \n",
    "                                           y_train=wine_train_y,\n",
    "                                           n_splits=3, \n",
    "                                           k_for_knn=3,\n",
    "                                           distance_type='euclidean_distance',\n",
    "                                           random_state=23)\n",
    "\n",
    "assert type(per_fold_accuracy) == np.ndarray\n",
    "np.testing.assert_almost_equal(per_fold_accuracy, np.array([0.92592593, 0.88461538, 0.96153846])) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea8216496c511fcf32d5db34c28faaa4",
     "grade": true,
     "grade_id": "kfold_cross_validation-hidden",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Remember, we will also use hidden test cases - you should create your own too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember**: Make sure to complete all problems (.ipynb files) in this assignment. When you finish, double-check the submission instructions at the top of this file, and submit on JupyterHub and Moodle."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
